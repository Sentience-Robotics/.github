# Sentience Robotics

## Overview

This project aims to develop an AI-driven software framework for humanoid robots, with InMoov as our primary testing platform.<br>
Our goal is to create a system that enables natural and dynamic human-robot interaction by integrating advanced AI models, including a custom model developed by our team.

The software will control the entire robot, not just facial expressions, enabling full-body movement and lifelike interactions.<br>
To enhance communication and interaction, we plan to integrate multiple AI models, such as large language models (LLMs), text-to-speech (TTS), and other specialized models.<br>
These will allow the robot to understand, respond, and engage in meaningful conversations while adapting to different scenarios.  By leveraging NVIDIA Isaac ROS2, we optimize real-time processing and motion control, ensuring smooth and intelligent responses. While InMoov serves as our initial testbed, our software is designed to be adaptable to other robotic platforms in the future.  Our project aims to enhance human-machine interaction while encouraging research in this field, keeping everything open source.  The two main parts of the project (software side) are:  


- Cervo: Creation of a framework enabling the use of any technology on the InMoov platform. We also include a safety layer using vision sensors to prevent accidents and harm.
- HuRI (Human Robot Interaction): An AI focusing on speech-to-speech interaction with a framework for short, medium, and long-term memory, alongside providing movement to any robotic platform to make interaction more natural.
- Additionally, we have a third team that builds and enhances the physical platform, called Thais.

### Why InMoov ?

We chose **InMoov** because it is an **open-source (Creative Commons) robot platform** designed by French sculptor and designer **Gael Langevin**. Its open-source nature and the strong community behind it provide an ideal foundation for experimentation, collaboration, and continuous improvement.  

<img src="https://github.com/user-attachments/assets/5527703e-4fa9-4ef3-88d6-c5726f98082a" width="50%">

## Technologies  
- **AI Integration**: Combining pre-trained models with a custom AI developed by our team.  
- **NVIDIA Isaac ROS2**: Leveraging NVIDIA's ROS2 framework for real-time robotic control and perception.  
- **Hardware**: We are also constructing the **InMoov** platform, enhancing its capabilities for human-like interaction.  

## Goals  
- Create lifelike facial expressions controlled by AI.  
- Seamlessly integrate custom and pre-existing AI models.  
- Optimize performance using NVIDIA Isaac ROS2.  

Stay tuned for updates as we push the boundaries of AI-driven robotics! ðŸš€

## The teams

Our project is divided into 3 teams, each focusing on a specific aspect of the project:

### Embedded Systems Team

- [Antoine ESMAN](https://github.com/Arcod7)
- [Axel CHYPRE](https://github.com/Cadavre-chan)
- [Charles MADJERI](https://github.com/charlesmadjeri)
- [MaÃ«l RABOT](https://github.com/Mael-RABOT)
- [Mathieu BOREL](https://github.com/m-brl)
- [Samuel BRUSCHET](https://github.com/sambrus)

### AI Team

- [Adrien AUDIARD](https://github.com/Popochounet)
- [Basile FOUQUET](https://github.com/b3ww)
- [Matthias VON RAKOWSKI](https://github.com/MatthiasvonRakowski)
- [Thomas POMMIER](https://github.com/thomas-pommier-epi)

### Hardware Team

- Dorianne BALLU
- Nathan

## Licences

All our project are licensed under the [GPL-3.0 License](https://www.gnu.org/licenses/gpl-3.0.fr.html) (GNU General Public License v3.0) if not otherwise specified.

## Contact

For any questions or inquiries, please contact us [here](mailto:contact@sentience-robotics.tech).
